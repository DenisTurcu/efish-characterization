{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from collections import OrderedDict\n",
    "from electric_images_dataset import ElectricImagesDataset\n",
    "from EndToEndConvNN import EndToEndConvNN\n",
    "from EndToEndConvNN_PL import EndToEndConvNN_PL\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../efish-physics-model/objects\")\n",
    "sys.path.append(\"../../efish-physics-model/helper_functions\")\n",
    "sys.path.append(\"../../efish-physics-model/uniform_points_generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_name = \"../../efish-physics-model/data/processed/data-2024_06_13-characterization_dataset\"\n",
    "# data_dir_name = \"../../efish-physics-model/data/processed/data-2024_06_13-characterization_dataset_mockup\"\n",
    "dataset = pd.read_pickle(f\"{data_dir_name}/dataset.pkl\")\n",
    "h5py_file = h5py.File(f\"{data_dir_name}/responses.hdf5\",'r')[\"responses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worm_id = 297135\n",
    "fish = dataset[\"fish\"][\"dataframe\"][\"objs\"][0]\n",
    "base_stim = dataset[\"electric_images\"][\"base\"][\"responses\"][0]\n",
    "modulation = (h5py_file[worm_id] / base_stim - 1) * 100\n",
    "modulation[fish.get_receptors_locations()[:,0]< -0.11] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish.visualize_scatter(intensity=modulation[:,0], show_normals=1, show_point_currents=5, marker_alpha=1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = modulation.reshape(30,20,2).transpose(1,0,2)[:,:,1]\n",
    "vval = np.max(np.abs(img_data))\n",
    "plt.imshow(img_data, cmap=\"viridis\", vmin=-vval, vmax=vval)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = ElectricImagesDataset(data_dir_name=data_dir_name, fish_t=20, fish_u=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = dset[worm_id][0][1]\n",
    "vval = np.max(np.abs(img_data))\n",
    "plt.imshow(img_data, cmap=\"viridis\", vmin=-vval, vmax=vval)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = DataLoader(dset, batch_size=4000, shuffle=True)\n",
    "batch = next(iter(dloader))\n",
    "batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"relu\"\n",
    "layers_properties = OrderedDict(\n",
    "    [\n",
    "        (\n",
    "            \"conv1\",\n",
    "            dict(in_channels=2, out_channels=8, kernel_size=5, stride=1, max_pool=dict(kernel_size=3, stride=1)),\n",
    "        ),\n",
    "        (\n",
    "            \"conv2\",\n",
    "            dict(in_channels=8, out_channels=32, kernel_size=5, stride=1, max_pool=dict(kernel_size=3, stride=1)),\n",
    "        ),\n",
    "        (\n",
    "            \"conv3\",\n",
    "            dict(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"conv4\",\n",
    "            dict(\n",
    "                in_channels=64,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"conv5\",\n",
    "            dict(in_channels=64, out_channels=32, kernel_size=3, stride=1, max_pool=dict(kernel_size=3, stride=2)),\n",
    "        ),\n",
    "        # the fully connected layers can have dropout or flatten layers - some can miss the activation\n",
    "        (\"fc1\", dict(dropout=0.5, flatten=True, in_features=None, out_features=512)),\n",
    "        (\"fc2\", dict(dropout=0.5, in_features=512, out_features=512)),\n",
    "        (\"fc3\", dict(in_features=512, out_features=6, activation=False)),\n",
    "    ]\n",
    ")\n",
    "if activation.lower() == \"relu\":\n",
    "    activation = nn.ReLU()\n",
    "elif activation.lower() == \"tanh\":\n",
    "    activation = nn.Tanh()\n",
    "else:\n",
    "    raise ValueError(f\"Activation {activation} not yet supported.\")\n",
    "model = EndToEndConvNN(layers_properties=layers_properties, activation=activation) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_model = model.forward_print_dims(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = model.sequence.conv1.conv.weight.detach().cpu().numpy()\n",
    "vval = np.max(np.abs(filters))\n",
    "f, ax = plt.subplots(filters.shape[1], filters.shape[0], figsize=(2*filters.shape[0], 2*filters.shape[1]))\n",
    "for i in range(filters.shape[1]):\n",
    "    for j in range(filters.shape[0]):\n",
    "        cbar_ax = ax[i, j].imshow(filters[j, i], cmap=\"seismic\", vmin=-vval, vmax=vval)\n",
    "        ax[i, j].set_xticks([])\n",
    "        ax[i, j].set_yticks([])\n",
    "        sns.despine(ax=ax[i, j], left=True, bottom=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset, valid_dset = torch.utils.data.random_split(dset, [0.8, 0.2])\n",
    "train_loader = DataLoader(train_dset, batch_size=64, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size=64, shuffle=False, drop_last=True)\n",
    "\n",
    "model_PL = EndToEndConvNN_PL(model)\n",
    "\n",
    "trainer = L.Trainer(max_steps=1000)\n",
    "trainer.fit(model=model_PL, train_dataloaders=train_loader, val_dataloaders=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "efish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
