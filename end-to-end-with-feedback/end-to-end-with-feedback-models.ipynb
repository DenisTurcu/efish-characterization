{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from collections import OrderedDict\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../end-to-end\")\n",
    "# sys.path.append(\"../../../electric_fish/ActiveZone/electrodynamic/objects\")\n",
    "# sys.path.append(\"../../../electric_fish/ActiveZone/electrodynamic/helper_functions\")\n",
    "# sys.path.append(\"../../../electric_fish/ActiveZone/electrodynamic/uniform_points_generation\")\n",
    "sys.path.append(\"../../efish-physics-model/objects\")\n",
    "sys.path.append(\"../../efish-physics-model/helper_functions\")\n",
    "sys.path.append(\"../../efish-physics-model/uniform_points_generation\")\n",
    "\n",
    "from electric_images_dataset import ElectricImagesDataset\n",
    "from EndToEndConvNN import EndToEndConvNN\n",
    "from EndToEndConvNN_PL import EndToEndConvNN_PL\n",
    "from EndToEndConvNNWithFeedback import EndToEndConvNNWithFeedback\n",
    "from EndToEndConvNNWithFeedback_PL import EndToEndConvNNWithFeedback_PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python train_end_to_end_models_with_feedback.py --input_noise_std 0.01 --save_dir small-with-values --use_estimates_as_feedback false --gpu 1\n",
    "# python train_end_to_end_models_with_feedback.py --input_noise_std 0.01 --save_dir small-with-estimates --use_estimates_as_feedback true --gpu 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"./with-values/lightning_logs/version_2/checkpoints/epoch=84-step=481950.ckpt\")\n",
    "# state_dict = torch.load(\"./with-estimates/lightning_logs/version_2/checkpoints/epoch=85-step=487620.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  1.,  1., 10., 20., 20.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict[\"hyper_parameters\"][\"loss_lambda\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers_properties': OrderedDict([('conv1',\n",
       "               {'in_channels': 1,\n",
       "                'out_channels': 8,\n",
       "                'kernel_size': 7,\n",
       "                'stride': 1,\n",
       "                'max_pool': {'kernel_size': 3, 'stride': 1}}),\n",
       "              ('conv2',\n",
       "               {'in_channels': 8,\n",
       "                'out_channels': 16,\n",
       "                'kernel_size': 5,\n",
       "                'stride': 1}),\n",
       "              ('conv3',\n",
       "               {'in_channels': 16,\n",
       "                'out_channels': 32,\n",
       "                'kernel_size': 5,\n",
       "                'stride': 1}),\n",
       "              ('conv4',\n",
       "               {'in_channels': 32,\n",
       "                'out_channels': 16,\n",
       "                'kernel_size': 5,\n",
       "                'stride': 1,\n",
       "                'max_pool': {'kernel_size': 3, 'stride': 1}}),\n",
       "              ('fc1', {'out_features': 5120}),\n",
       "              ('fc2', {'in_features': 5120, 'out_features': 2560}),\n",
       "              ('fc3', {'in_features': 2560, 'out_features': 1280}),\n",
       "              ('fc4', {'in_features': 1280, 'out_features': 4})]),\n",
       " 'activation_spatial': 'relu',\n",
       " 'model_type': 'two_paths',\n",
       " 'kernel_size': 7,\n",
       " 'in_channels': 2,\n",
       " 'poly_degree_distance': 4,\n",
       " 'poly_degree_radius': 3,\n",
       " 'activation_feedback': 'relu',\n",
       " 'use_estimates_as_feedback': True,\n",
       " 'input_noise_std': 0.01,\n",
       " 'input_noise_type': 'additive',\n",
       " 'loss_lambda': tensor([1., 1., 1., 1., 2., 2.])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict[\"hyper_parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "efish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
